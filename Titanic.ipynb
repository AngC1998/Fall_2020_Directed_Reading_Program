{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", dpi=300, figsize=(9,3))\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Titanic Survival Estimation via Naïve Bayes</h1>\n",
    "<h2 align=\"center\">Angela Cao</h2>\n",
    "<h5 align=\"center\">Fall 2020 Directed Readings Program, University of Texas at Austin Department of Mathematics</h4>\n",
    "<h5 align=\"center\">Advised by Shane McQuarrie</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [**Introduction: The Titanic Problem**](#Introduction:-The-Titanic-Problem)\n",
    "2. [**Brief Data Summary**](#Brief-Data-Summary)\n",
    "3. [**The Naïve Bayes Algorithm**](#The-Naïve-Bayes-Algorithm)\n",
    "4. [**Applying the Algorithm**](#Applying-the-Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: The Titanic Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On April 15, 1912, the [RMS Titanic](https://en.wikipedia.org/wiki/Titanic) sank, leaving about 1,500 people dead. The goal of this project is to construct a machine learning algorithm to predict whether or not a person with given characteristics would have been likely to survive the accident. This is a [popular problem](https://www.kaggle.com/c/titanic) for a first-time exposure to machine learning.\n",
    "\n",
    "We have a [data set](https://www.kaggle.com/c/titanic/data) with information about 1,308 of the Titanic passengers, with the following features for each passenger. We begin by loading the data and displaying a few random entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from file.\n",
    "titanic_original = pd.read_csv(\"titanic.csv\")\n",
    "titanic_original.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of these features differentiate a survivor from a nonsurvivor? We restrict our attention to the following features:\n",
    "- `Sex`: the sex of the passenger, either `male` or `female`.\n",
    "- `Age`: the age of the passenger, usually recorded as a positive integer.\n",
    "- `Pclass`: the class of the passenger's ticket, 1 for first class (the best), 2 for second class, and 3 for third class (the worst).\n",
    "- `Fare`: the cost of the passenger's ticket.\n",
    "\n",
    "Some of the other columns in the data may be useful, but certainly these features are more important survival indicators than, for example, the passenger `Name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant columns.\n",
    "titanic = titanic_original[[\"Survived\", \"Sex\", \"Age\", \"Pclass\", \"Fare\"]]\n",
    "titanic.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any analysis, we split the data into training and testing sets, reserving 15% of the entries for testing. We are only allowed to use the testing set to evaluate the performance of our algorithm later on. Since some of the entries of the data may be missing (for example, some passengers don't have a recorded age), we replace missing values of the test data with the column averages of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets.\n",
    "train_data, test_data = train_test_split(titanic, test_size=.15)\n",
    "print(f\"{len(train_data)} train points, {len(test_data)} test points ({len(titanic)} total)\")\n",
    "\n",
    "# Separate the Survival labels from the test data and replace\n",
    "# missing values with the averages from the training data.\n",
    "test_labels = test_data[\"Survived\"]\n",
    "test_data = test_data.drop(\"Survived\", axis=1).fillna(train_data.mean())\n",
    "\n",
    "test_data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Data Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before describing the algorithm, we give a brief statistical overview of the training data (remember, we aren't allowed to even look at the testing data). First, what was the rate of survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(9, 2))\n",
    "\n",
    "survival_count = train_data.groupby(\"Survived\").count().max(axis=1)\n",
    "survival_count.plot(kind=\"barh\", ax=ax)\n",
    "\n",
    "ax.set_ylabel(\"\"); ax.set_yticklabels([\"perished\", \"survived\"])\n",
    "ax.set_xlabel(\"number of passengers\")\n",
    "ax.set_title(f\"Passenger Survival Rate: {survival_count[1] / sum(survival_count):.2%}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(9,2))\n",
    "\n",
    "train_data[\"Age\"].plot(kind=\"hist\", bins=80, ax=ax1)\n",
    "ax1.set_xlabel(\"passenger age\")\n",
    "\n",
    "train_data[\"Fare\"].plot(kind=\"hist\", bins=40, ax=ax2)\n",
    "ax2.set_ylabel(\"\"); ax2.set_xlabel(\"ticket fare\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram on the left shows the distribution of the ages of the passengers in the training data. The distribution is slightly right-skewed with a good amount of passengers in their 20's and 30's and also a good chunk of children as well.\n",
    "\n",
    "The histogram on the right shows the distribution of the ticket prices of the passengers in the training data. This distribution is extremely right-skewed, with the overwhelming majority of passengers having tickets that cost \\$100  or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we briefly look for statistical differences between survivors and nonsurvivors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.groupby([\"Survived\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table sorts the data by the survival label (0 for non-survivors and 1 for survivors), then computes mean of the columns for each group. A few things are immediate apparent:\n",
    "- Survivors had, on average, significantly more expensive tickets than non-survivors.\n",
    "- **Something about the Pclass**\n",
    "\n",
    "In short, the survivors and non-survivors exhibit different statistics; we aim to use that information to construct a \"survival classifier.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Naïve Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to construct a function that maps a given tuple of `Sex`, `Age`, `Pclass`, and `Fare` values to a `Survival` value (0 for perished or 1 for survived).\n",
    "There are many ways to construct such a function, but we will use the simple Naïve Bayes algorithm.\n",
    "This is a _binary classification problem_ because we are separating instances of data into two categories, and since we have labeled data to train on, this is an example of _supervised learning_. Naïve Bayes can also be used for multi-class classification (more than two categories to sort the data into), but we restrict ourselves to the binary case for ease of exposition. We will first develop the algorithm generally, then show how it applies specifically to the Titanic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $P$ be a probability measure and let $A$ and $B$ be events in the probability space. _Bayes' rule_ is the statement\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}.\n",
    "$$\n",
    "\n",
    "Suppose we have $n$ features (kinds of data to train on) $X_1,\\ldots,X_n$ and let $Y$ denote the label corresponding to these features. We use Bayes' rule to write\n",
    "\n",
    "$$\n",
    "P(Y=i\\mid X_1,\\ldots,X_n) = \\frac{P(X_1,\\ldots,X_n\\mid Y=i)P(Y=i)}{P(X_1,\\ldots,X_n)}.\n",
    "$$\n",
    "\n",
    "The left-hand side is the probability that the tuple of data $(X_1,\\ldots,X_n)$ belongs to the class $Y = i$.\n",
    "The right-hand side has three elements:\n",
    "- The probability $P(Y=i)$ is called the _prior_, which is our initial guess for the probability of an arbitrary set of data belonging to the class $Y = i$.\n",
    "- The denominator $P(X_1,\\ldots,X_n)$ is called the _evidence_, which is the normalization factor for the conditional probability.\n",
    "- The conditional probability $P(X_1,\\ldots,X_n \\mid Y=i)$ is the _likelihood_, the probability of observing this specific data given that it belongs to the class $Y = i$. This is usually the trickiest part to compute in a Bayesian inference problem, but we will make an assumption that makes it easy to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with the evidence, we use with the _Law of Total Probability_:\n",
    "\n",
    "$$\n",
    "P(X_1,\\ldots,X_n) = \\sum_{i\\in\\{0,1\\}} P(X_1,\\ldots,X_n|Y=i)P(Y=i).\n",
    "$$\n",
    "\n",
    "In other words, the evidence can be written in terms of the likelihoods and priors. To compute the likelihood, we use the (naïve!) assumption that **the data features are conditionally independent**, that is,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    P(X_1,\\ldots,X_n|Y=i)\n",
    "    &= \\prod_{j=1}^{n}P(X_{j}|Y = i)\n",
    "    \\\\\n",
    "    &= P(X_1|Y=i)P(X_2|Y=i)\\cdots P(X_n|Y=i)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**_Write a little bit here about why this may or may not be a good idea._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute each $P(X_j|Y=i)$, we need to choose probability distributions for each $X_j$. We'll give two examples.\n",
    "1. If $X_1$ can take on two values 0 and 1 (e.g., in the titanic data, `Sex` is either `male` or `female`), then we choose a Bernoulli distribution to model the probability distribution of $X_1$, that is,\n",
    "<!--  -->\n",
    "$$\n",
    "\\begin{align*}\n",
    "    P(X_1 = 1 \\mid Y = i) &= q_i\n",
    "    &\n",
    "    P(X_1 = 0 \\mid Y = i) &= 1 - q_i\n",
    "\\end{align*}\n",
    "$$\n",
    "<!--  -->\n",
    "We estimate $q_i$ from the training data by counting the number of instances where $X_1 = 1$ among the group where $Y = i$. That is,\n",
    "<!--  -->\n",
    "$$\n",
    "\\begin{align*}\n",
    "    q_i = \\frac{\\textrm{# data points with}\\ X_1 = 1, Y = i}{\\textrm{total # of data points with}\\ Y = i}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "2. For a continuous feature, we need to select and calibrate a continuous distribution. For example, we may assume $X_2$ has a Gaussian (Normal) distribution, defined by the mean $\\mu$ and standard deviation $\\sigma$. To estimate $\\mu$ and $\\sigma$ for each group, we again use the training data:\n",
    "<!--  -->\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mu_{i} &= \\textrm{mean}\\left(\\textrm{values of}\\ X_2\\ \\textrm{where}\\ Y = i\\right)\n",
    "    \\\\\n",
    "    \\sigma_{i} &= \\textrm{standard deviation}\\left(\\textrm{values of}\\ X_2\\ \\textrm{where}\\ Y = i\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "<!--  -->\n",
    "We then compute $P(X_2 \\mid Y = i)$ by evaluating the probability density function of the normal distribution $\\mathcal{N}(\\mu,\\sigma)$ at the value of $X_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute $P(Y = i \\mid X_1,\\ldots,X_n)$ for any sample of data $X_1,\\ldots,X_n$. To classify the data, we simply pick the most probable label.\n",
    "\n",
    "$$\n",
    "    \\textrm{label of data}\\ (X_1,\\ldots,X_n)\n",
    "    = \\underset{i\\in\\{0,1\\}}{\\textrm{argmax}}\\ P(Y = i \\mid X_1,\\ldots,X_n).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pros and Cons\n",
    "\n",
    "**_List some pros and cons here. A few that I can think of are below, but you should rewrite / expand on this._**\n",
    "- It's _scalable_, meaning it's cheap to do for really large data sets.\n",
    "- It's highly interpretable: it gives you a probability for each class (so the uncertainty of the prediction is quantified) and you can look at each of the distributions it learns to understand its decision-making process.\n",
    "- It's easy to implement, as we see below.\n",
    "- It doesn't require any preprocessing like scaling.\n",
    "- But it's naïve! If the features are interdependent or have subtle relationships we'll run into trouble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application to the Titanic Data\n",
    "\n",
    "We want the probability of survival given the features in the data, so we want to compute\n",
    "\n",
    "$$\n",
    "P(\\textrm{Survived} \\mid \\textrm{Sex,Age,Pclass,Fare})\n",
    "= \\frac{P(\\textrm{Sex,Age,Pclass,Fare} \\mid \\textrm{Survived})P(\\textrm{Survived})}{P(\\textrm{Sex,Age,Pclass,Fare})}.\n",
    "$$\n",
    "\n",
    "To build a Naïve Bayes classifier, we need to choose distributions for each of the data features.\n",
    "- $X_1$ = Sex. This is a binary variable, so we model it with a Bernoulli distribution.\n",
    "- $X_2$\n",
    "- $X_3$ Categorical (Bernoulli but with more than two possible outcomes)\n",
    "- $X_4$ Exponential (or Gaussian)\n",
    "\n",
    "**_Explain why we choose each of these (refer to the graphs in the data visualization section)_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNaiveBayes:\n",
    "    \"\"\"Naïve Bayes classifier for the Titanic problem, mapping values of\n",
    "    Sex, Age, Fare, and Pclass to Survival.\n",
    "    \"\"\"\n",
    "    def fit(self, data):\n",
    "        \"\"\"Calculate statistics for each group based on survival.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data to train on.\n",
    "        \"\"\"\n",
    "        for i in range(0, 2):\n",
    "            total = 0\n",
    "            males = 0\n",
    "            mean = 0.0\n",
    "            ages = []\n",
    "            std = 0.0\n",
    "            for k in range(0, len(data)):\n",
    "                status = labels[k]\n",
    "                if status == i:\n",
    "                    total += 1\n",
    "                    if data.iloc[k][0] == 'male':\n",
    "                        males += 1\n",
    "                    mean += data.iloc[k][1]\n",
    "                    ages.append(data.iloc[k][1])\n",
    "            probability = (total * 1.0) / len(data)\n",
    "            males = (males * 1.0) / (total * 1.0)\n",
    "            mean = (mean * 1.0) / (total * 1.0)\n",
    "            for k in range(0, len(ages)):\n",
    "                std += pow((ages[k] - mean), 2)\n",
    "                std = std / (total * 1.0)\n",
    "                std = sqrt(std)\n",
    "            print(\"Group \"+str(i))\n",
    "            print(\"Probability = \"+str(probability))\n",
    "            print(\"Mean = \"+str(mean))\n",
    "            print(\"Standard Deviation = \"+str(std))\n",
    "        return self\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"Calculate the probabilities of belonging to each distribution.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pd.DataFrame\n",
    "            Data to train on.\n",
    "        \"\"\"\n",
    "        denom = 0\n",
    "        prob_group = [0.0, 0.0]\n",
    "        for i in range(0, 2):\n",
    "            females = 0\n",
    "            males = 0\n",
    "            mean = 0.0\n",
    "            ages = []\n",
    "            std = 0.0\n",
    "            total = 0\n",
    "            for k in range(0, len(data)):\n",
    "                status = labels[k]\n",
    "                if status == i:\n",
    "                    total += 1\n",
    "                    if data.iloc[k][0] == 'male':\n",
    "                        males += 1\n",
    "                    else:\n",
    "                        females += 1\n",
    "                    mean += data.iloc[k][1]\n",
    "                    ages.append(data.iloc[k][1])\n",
    "            females = (females * 1.0) / (total * 1.0)\n",
    "            males = (males * 1.0) / (total * 1.0)\n",
    "            mean = (mean * 1.0) / (total * 1.0)\n",
    "            for k in range(0, len(ages)):\n",
    "                std += pow((ages[k] - mean), 2)\n",
    "                std = std / (total * 1.0)\n",
    "                std = sqrt(std)\n",
    "            ### idk about the rest lol\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNaiveBayes:\n",
    "    \"\"\"Naïve Bayes classifier for the Titanic problem, mapping values of\n",
    "    Sex, Age, Fare, and Pclass to Survival.\n",
    "    \"\"\"\n",
    "    def fit(self, data):\n",
    "        \"\"\"Calculate statistics for each group based on survival.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data to train on.\n",
    "        \"\"\"\n",
    "        groups = data.groupby(\"Survived\")\n",
    "\n",
    "        sex_params = {}\n",
    "        age_params = {}\n",
    "        fare_params = {}\n",
    "        pclass_params = {}\n",
    "\n",
    "        for Y, group in groups:\n",
    "            # Get the average number of males in the group.\n",
    "            sex_params[Y] = np.mean(group[\"Sex\"] == \"male\")\n",
    "\n",
    "            # Get the mean and standard deviation of the ages in the group.\n",
    "            age_params[Y] = np.mean(group[\"Age\"]), np.std(group[\"Age\"])\n",
    "\n",
    "            # Get the mean and standard deviation of the fare in the group.\n",
    "            fare_params[Y] = np.mean(group[\"Fare\"]), np.std(group[\"Fare\"])\n",
    "\n",
    "            # Get the probability for each class in the group.\n",
    "            pclass_params[Y] = [np.mean(group[\"Pclass\"] == j) for j in [1,2,3]]\n",
    "\n",
    "        self.sex_params_ = sex_params\n",
    "        self.age_params_ = age_params\n",
    "        self.fare_params_ = fare_params\n",
    "        self.pclass_params_ = pclass_params\n",
    "        return self\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"Calculate the probabilities of belonging to each distribution.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pd.DataFrame\n",
    "            Data to train on.\n",
    "        \"\"\"\n",
    "        probabilities = []\n",
    "        for row in data.values:\n",
    "            numerators = []\n",
    "            for Y in [0,1]:\n",
    "                q = self.sex_params_[Y]\n",
    "                p1 = q if data[\"Sex\"] == \"male\" else 1 - q\n",
    "\n",
    "                m2, s2 = self.age_params_[Y]\n",
    "                p2 = stats.norm(m2, s2).pdf(data[\"Age\"])\n",
    "\n",
    "                m2, s2 = self.age_params_[Y]\n",
    "                p3 = self.age_params_[Y]\n",
    "\n",
    "                qs = self.pclass_params_[Y]\n",
    "                p4 = qs[int(data[\"Pclass\"]) - 1]\n",
    "\n",
    "                numerators.append(np.exp(np.sum(np.log([p1, p2, p3, p4, .5]))))\n",
    "\n",
    "            denom = sum(numerators)\n",
    "            probabilities.append(np.array(numerators) / denom)\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNaiveBayes2:\n",
    "    \"\"\"Naïve Bayes classifier for the Titanic problem, mapping values of\n",
    "    Sex, Age, Fare, and Pclass to Survival (0 = perished, 1 = survived).\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    prior_ : scipy.stats Bernoulli distribution\n",
    "        Survival probability prior, i.e., prior_.pmf(Y) returns the\n",
    "        probability of perishing if Y = 0 or surviving if Y = 1.\n",
    "\n",
    "    likelihood_ : dict[Y -> scipy.stats distributions]\n",
    "        Independent likelihood probability distributions whose parameters\n",
    "        are computed from the training data. In order:\n",
    "        * Sex: Bernoulli\n",
    "        * Age: Gaussian (normal)\n",
    "        * Fare: Exponential\n",
    "        * Pclass: Categorical\n",
    "    \"\"\"\n",
    "    def __init__(self, survival_prior=.5):\n",
    "        \"\"\"Set the probability of survival (Benoulli prior distribution).\"\"\"\n",
    "        self.prior_ = stats.bernoulli(survival_prior)\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Calculate statistics for each group based on survival.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data to train on. Must have columns\n",
    "            [\"Survived\", \"Sex\", \"Age\", \"Fare\", \"Pclass\"].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        groups = data.groupby(\"Survived\")\n",
    "        self.likelihood_ = {}\n",
    "\n",
    "        for Y, group in groups:\n",
    "            # Record the label.\n",
    "            distributions = {}\n",
    "\n",
    "            # Sex distribution: Bernoulli.\n",
    "            q = np.mean(group[\"Sex\"] == \"male\")\n",
    "            distributions[\"Sex\"] = stats.bernoulli(q)\n",
    "\n",
    "            # Age distribution: Gaussian (Normal).\n",
    "            µ, σ = group[\"Age\"].mean(), group[\"Age\"].std()\n",
    "            distributions[\"Age\"] = stats.norm(µ, σ)\n",
    "\n",
    "            # Fare distribution: Exponential.\n",
    "            loc, scale = stats.expon.fit(group[\"Fare\"].dropna())\n",
    "            distributions[\"Fare\"] = stats.expon(loc, scale)\n",
    "\n",
    "            # Pclass distribution: Categorical.\n",
    "            qs = np.array([np.mean(group[\"Pclass\"] == j) for j in [1,2,3]])\n",
    "            distributions[\"Pclass\"] = qs\n",
    "\n",
    "            self.likelihood_[Y] = distributions\n",
    "\n",
    "        return self\n",
    "\n",
    "    def proba(self, data):\n",
    "        \"\"\"Calculate the probabilites of each row of data belonging to each\n",
    "        survival category via Bayes' rule:\n",
    "\n",
    "                                        P(features | Survived=i) P(Survived)\n",
    "        P(Survived=i | features) = ---------------------------------------------\n",
    "                                   sum_{j}[P(features | Survived=j) P(Survived)]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : (m,4) pd.DataFrame\n",
    "            Data to make a prediction for. Must have columns\n",
    "            [\"Sex\", \"Age\", \"Fare\", \"Pclass\"].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probabilities : (m,2) ndarray\n",
    "            Perish / survival probabilities.\n",
    "        \"\"\"\n",
    "        numerators = []\n",
    "        for Y in self.likelihood_:\n",
    "            dist = self.likelihood_[Y]\n",
    "\n",
    "            # Evaluate the likelihood and prior distributions.\n",
    "            pXs = [dist[\"Sex\"].pmf(data[\"Sex\"] == \"male\"),        # P(Sex|Y)\n",
    "                   dist[\"Age\"].pdf(data[\"Age\"]),                  # P(Age|Y)\n",
    "                   dist[\"Fare\"].pdf(data[\"Fare\"]),                # P(Fare|Y)\n",
    "                   dist[\"Pclass\"][np.int32(data[\"Pclass\"]) - 1],  # P(Pclass|Y)\n",
    "                   self.prior_.pmf([Y]*len(data))                 # P(Y)\n",
    "                   ]\n",
    "\n",
    "            numerators.append(np.exp(np.sum(np.log(pXs), axis=0)))\n",
    "        numers = np.array(numerators)\n",
    "\n",
    "        return np.transpose(numers / np.sum(numers, axis=0))\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"Predict a survival category for each row of data via Bayes' rule.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : (m,4) pd.DataFrame\n",
    "            Data to make a prediction for. Must have columns\n",
    "            [\"Sex\", \"Age\", \"Fare\", \"Pclass\"].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : (m,) ndarray\n",
    "            Perish / survival probabilities.\n",
    "        \"\"\"\n",
    "        return np.argmax(self.proba(data), axis=-1)\n",
    "\n",
    "    def accuracy(self, data, labels):\n",
    "        \"\"\"Compute the accuracy of the model given some test data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : (m,4) pd.DataFrame\n",
    "            Data to make a prediction for. Must have columns\n",
    "            [\"Sex\", \"Age\", \"Fare\", \"Pclass\"].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        accuracy : float\n",
    "            The % of rows guessed correctly.\n",
    "        \"\"\"\n",
    "        return np.mean(self.predict(data) == labels)\n",
    "\n",
    "    # Distribution plots ------------------------------------------------\n",
    "    def _survival_label(self, Y):\n",
    "        return \"Perished\" if Y == 0 else \"Survived\"\n",
    "\n",
    "    def plot_prior(self):\n",
    "        data = pd.DataFrame(index=[\"Perished\", \"Survived\"],\n",
    "                            columns=[\"Prior\"])\n",
    "        data[\"Prior\"] = self.prior_.pmf([0,1])\n",
    "        data.plot(kind=\"barh\")\n",
    "        plt.legend([])\n",
    "        plt.title(\"Prior Survival Distribution\")\n",
    "\n",
    "    def plot_sex(self):\n",
    "        sexes = np.array([0, 1])\n",
    "        data = pd.DataFrame(index=[\"Perished\", \"Survived\"],\n",
    "                            columns=[\"Female\", \"Male\"])\n",
    "        for Y, distributions in self.likelihood_.items():\n",
    "            data.loc[self._survival_label(Y)] = distributions[\"Sex\"].pmf(sexes)\n",
    "        data.plot(kind=\"barh\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.title(\"Estimated Sex Distributions\")\n",
    "\n",
    "    def plot_age(self):\n",
    "        years = np.linspace(0, 100, 1000)\n",
    "        for Y, distributions in self.likelihood_.items():\n",
    "            plt.plot(years, distributions[\"Age\"].pdf(years),\n",
    "                     label=self._survival_label(Y))\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.title(\"Estimated Age Distributions\")\n",
    "\n",
    "    def plot_fare(self):\n",
    "        fares = np.linspace(0, 550, 1000)\n",
    "        for Y, distributions in self.likelihood_.items():\n",
    "            plt.plot(fares, distributions[\"Fare\"].pdf(fares),\n",
    "                     label=self._survival_label(Y))\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.title(\"Estimated Fare Distributions\")\n",
    "\n",
    "    def plot_pclass(self):\n",
    "        data = pd.DataFrame(index=[\"Perished\", \"Survived\"],\n",
    "                            columns=[\"1st Class\", \"2nd Class\", \"3rd Class\"])\n",
    "        for Y, distributions in self.likelihood_.items():\n",
    "            data.loc[self._survival_label(Y)] = distributions[\"Pclass\"]\n",
    "        data.plot(kind=\"barh\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.title(\"Estimated Pclass Distributions\")\n",
    "\n",
    "    def plot_likelihoods(self):\n",
    "        \"\"\"Plot each of the learned distributions.\"\"\"\n",
    "        self.plot_prior()\n",
    "        plt.show()\n",
    "        self.plot_sex()\n",
    "        plt.show()\n",
    "        self.plot_age()\n",
    "        plt.show()\n",
    "        self.plot_fare()\n",
    "        plt.show()\n",
    "        self.plot_pclass()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use Naïve Bayes on the Titanic data, we should check the assumption of conditional independence among the training variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are these variables correlated?\n",
    "train_data.drop(\"Survived\", axis=1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_This is why we \\*might\\* have a chance with Naïve Bayes, it looks like the features aren't too interdependent._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = TitanicNaiveBayes2(.4).fit(train_data)\n",
    "nb.plot_likelihoods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb.accuracy(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = test_data.sample(5)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.proba(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[samples.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[np.argmax(nb.proba(test_data), axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: More Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(\"Pclass\").count()[\"Age\"].plot(kind=\"barh\")\n",
    "plt.title(\"Passenger Count by Ticket Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only shows the amount of passengers recorded in the data through the 'Survived' column (1309 passengers recorded, and most of them probably perished according to the mean and quartiles), but also the number of passengers in the data who got their ages recorded and the mean and ranges of ages recorded, and the mean and ranges of classes and fares recorded as well through min, quartiles, and max. \n",
    "\n",
    "From the table, we can see that: \n",
    "- The majority of passengers recorded perished in the Titanic incident. \n",
    "- There were 1046 passengers whose ages were recorded in the data. Some passengers are missing ages. \n",
    "- The mean age of the passsengers in the Titanic were 29-30 years old. \n",
    "- The median age of the passengers in the Titanic is about 28 years old which confirms the right-skewness of the distribution of ages. \n",
    "- The youngest passenger was a baby while the oldest passenger is 80 years old. \n",
    "- A good majority of passengers recorded bought 3rd class tickets though the mean (average) was is about 2nd class. \n",
    "- The mean fare of the passengers in the Titanic was about 33.30 dollars. \n",
    "- The median fare of the passengers in the Titanic was about 14.45 dollars which confirms the extreme right-skewness of the distribution of fare. \n",
    "- The cheapest ticket was for free while the most expensive ticket was about 512.33 dollars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows all the passengers in the data whose ages are unknown so far. According to the table, there are 263 entries or passengers whose ages were not recorded and one passenger with a missing ticket fare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Survived Classification Data Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_groups = titanic.groupby(\"Survived\")\n",
    "survival_groups.boxplot(grid=False, column=['Age'], layout=(1,2))\n",
    "survival_groups.boxplot(grid=False, column=['Fare'], layout=(1,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pclass Classification Data Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = titanic.groupby(\"Pclass\")\n",
    "groups.boxplot(grid=False, column=['Age'], layout=(1,3))\n",
    "groups.boxplot(grid=False, column=['Fare'], layout=(1,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sex Classification Data Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_groups = titanic.groupby(\"Sex\")\n",
    "gender_groups.boxplot(grid=False, column=['Age'], layout=(1,2))\n",
    "gender_groups.boxplot(grid=False, column=['Fare'], layout=(1,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age and Fare as Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the passengers into 3 categories based on age.\n",
    "age = pd.cut(titanic['Age'], [0, 12, 18, 80])\n",
    "age\n",
    "\n",
    "titanic.pivot_table(values='Survived', index=['Sex', age],\n",
    "                   columns='Pclass', aggfunc='mean')\n",
    "\n",
    "titanic.pivot_table(values='Survived', index=['Sex', age],\n",
    "                   columns='Pclass', aggfunc='count')\n",
    "\n",
    "# Cut the ticket price into two intervals (cheap vs expensive)\n",
    "fare = pd.qcut(titanic['Fare'], 2)\n",
    "fare\n",
    "\n",
    "titanic.pivot_table(values='Survived',\n",
    "                   index=['Sex', age], columns=[fare, 'Pclass'],\n",
    "                   aggfunc='count', fill_value='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age and Fare Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.plot(kind='scatter', x='Age', y='Fare', alpha=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
